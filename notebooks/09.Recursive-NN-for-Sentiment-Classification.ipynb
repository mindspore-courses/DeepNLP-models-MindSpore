{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Recursive Neural Networks and Constituency Parsing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I recommend you take a look at these material first."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* http://web.stanford.edu/class/cs224n/lectures/cs224n-2017-lecture14-TreeRNNs.pdf\n",
    "* https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:32.591801Z",
     "iopub.status.busy": "2023-07-26T14:17:32.591408Z",
     "iopub.status.idle": "2023-07-26T14:17:34.706155Z",
     "shell.execute_reply": "2023-07-26T14:17:34.705557Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WARNING] ME(2325139:139790637999936,MainProcess):2023-07-26-22:17:33.140.050 [mindspore/run_check/_check_version.py:102] MindSpore version 2.0.0.20230623 and cuda version 11.7.60 does not match, CUDA version [['10.1', '11.1', '11.6']] are supported by MindSpore officially. Please refer to the installation guide for version matching information: https://www.mindspore.cn/install.\n",
      "/home/daiyuxin/anaconda3/envs/cjh1/lib/python3.7/site-packages/mindnlp/utils/download.py:29: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import mindspore\n",
    "from mindspore import nn, ops, Tensor, Parameter, ParameterTuple\n",
    "import random\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "from mindnlp.modules import Accumulator\n",
    "from IPython.display import display\n",
    "from nltk.tree import Tree as nltkTree\n",
    "from mindspore.common.initializer import initializer\n",
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "random.seed(1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.709436Z",
     "iopub.status.busy": "2023-07-26T14:17:34.709004Z",
     "iopub.status.idle": "2023-07-26T14:17:34.711986Z",
     "shell.execute_reply": "2023-07-26T14:17:34.711523Z"
    }
   },
   "outputs": [],
   "source": [
    "gpu = '0'\n",
    "# 设置使用哪些显卡进行训练\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.714276Z",
     "iopub.status.busy": "2023-07-26T14:17:34.713994Z",
     "iopub.status.idle": "2023-07-26T14:17:34.717695Z",
     "shell.execute_reply": "2023-07-26T14:17:34.717249Z"
    }
   },
   "outputs": [],
   "source": [
    "def getBatch(batch_size, train_data):\n",
    "    random.shuffle(train_data)\n",
    "    sindex = 0\n",
    "    eindex = batch_size\n",
    "    while eindex < len(train_data):\n",
    "        batch = train_data[sindex: eindex]\n",
    "        temp = eindex\n",
    "        eindex = eindex + batch_size\n",
    "        sindex = temp\n",
    "        yield batch\n",
    "\n",
    "    if eindex >= len(train_data):\n",
    "        batch = train_data[sindex:]\n",
    "        yield batch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stanford Sentiment Treebank(https://nlp.stanford.edu/sentiment/index.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.720688Z",
     "iopub.status.busy": "2023-07-26T14:17:34.720325Z",
     "iopub.status.idle": "2023-07-26T14:17:34.777772Z",
     "shell.execute_reply": "2023-07-26T14:17:34.777223Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4 (3 (2 (1 -LRB-) (2 (2 A) (3 -RRB-))) (4 (3 (4 (3 wonderfully) (1 loopy)) (2 tale)) (3 (2 of) (2 (3 (3 (3 (2 (4 love) (2 ,)) (2 longing)) (2 ,)) (2 and)) (2 voting))))) (2 .))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sample = random.choice(open('../dataset/trees/train.txt', 'r', encoding='utf-8').readlines())\n",
    "print(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.780582Z",
     "iopub.status.busy": "2023-07-26T14:17:34.780228Z",
     "iopub.status.idle": "2023-07-26T14:17:34.823633Z",
     "shell.execute_reply": "2023-07-26T14:17:34.823128Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg baseProfile=\"full\" height=\"504px\" preserveAspectRatio=\"xMidYMid meet\" style=\"font-family: times, serif; font-weight:normal; font-style: normal; font-size: 16px;\" version=\"1.1\" viewBox=\"0,0,672.0,504.0\" width=\"672px\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:ev=\"http://www.w3.org/2001/xml-events\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg><svg width=\"96.4286%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"20.9877%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"41.1765%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">1</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-LRB-</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.5882%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"58.8235%\" x=\"41.1765%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"30%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">A</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"15%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"70%\" x=\"30%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">-RRB-</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"65%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.5882%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"10.4938%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"79.0123%\" x=\"20.9877%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg><svg width=\"40.625%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"76.9231%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg><svg width=\"65%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">wonderfully</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"32.5%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"35%\" x=\"65%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">1</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">loopy</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"82.5%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.4615%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.0769%\" x=\"76.9231%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">tale</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.4615%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"20.3125%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"59.375%\" x=\"40.625%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"10.5263%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">of</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"5.26316%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"89.4737%\" x=\"10.5263%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"76.4706%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"80.7692%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"85.7143%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">3</text></svg><svg width=\"50%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"66.6667%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">4</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">love</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"33.3333%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"33.3333%\" x=\"66.6667%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"83.3333%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"25%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"50%\" x=\"50%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">longing</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"75%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"42.8571%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"14.2857%\" x=\"85.7143%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">,</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"92.8571%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"40.3846%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"19.2308%\" x=\"80.7692%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">and</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"90.3846%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"38.2353%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"23.5294%\" x=\"76.4706%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">voting</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"88.2353%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"55.2632%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"70.3125%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"60.4938%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"48.2143%\" y1=\"1.2em\" y2=\"3em\" /><svg width=\"3.57143%\" x=\"96.4286%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">2</text></svg><svg width=\"100%\" x=\"0%\" y=\"3em\"><defs /><svg width=\"100%\" x=\"0\" y=\"0em\"><defs /><text text-anchor=\"middle\" x=\"50%\" y=\"1em\">.</text></svg></svg><line stroke=\"black\" x1=\"50%\" x2=\"50%\" y1=\"1.2em\" y2=\"3em\" /></svg><line stroke=\"black\" x1=\"50%\" x2=\"98.2143%\" y1=\"1.2em\" y2=\"3em\" /></svg>"
      ],
      "text/plain": [
       "Tree('4', [Tree('3', [Tree('2', [Tree('1', ['-LRB-']), Tree('2', [Tree('2', ['A']), Tree('3', ['-RRB-'])])]), Tree('4', [Tree('3', [Tree('4', [Tree('3', ['wonderfully']), Tree('1', ['loopy'])]), Tree('2', ['tale'])]), Tree('3', [Tree('2', ['of']), Tree('2', [Tree('3', [Tree('3', [Tree('3', [Tree('2', [Tree('4', ['love']), Tree('2', [','])]), Tree('2', ['longing'])]), Tree('2', [','])]), Tree('2', ['and'])]), Tree('2', ['voting'])])])])]), Tree('2', ['.'])])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tree = nltkTree.fromstring(sample)\n",
    "display(tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Class "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "borrowed code from https://github.com/bogatyy/cs224d/tree/master/assignment3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.826880Z",
     "iopub.status.busy": "2023-07-26T14:17:34.826480Z",
     "iopub.status.idle": "2023-07-26T14:17:34.945339Z",
     "shell.execute_reply": "2023-07-26T14:17:34.944772Z"
    }
   },
   "outputs": [],
   "source": [
    "class Node:  # a node in the tree\n",
    "    def __init__(self, label, word=None):\n",
    "        self.label = label\n",
    "        self.word = word\n",
    "        self.parent = None  # reference to parent\n",
    "        self.left = None  # reference to left child\n",
    "        self.right = None  # reference to right child\n",
    "        # true if I am a leaf (could have probably derived this from if I have\n",
    "        # a word)\n",
    "        self.isLeaf = False\n",
    "        # true if we have finished performing fowardprop on this node (note,\n",
    "        # there are many ways to implement the recursion.. some might not\n",
    "        # require this flag)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.isLeaf:\n",
    "            return '[{0}:{1}]'.format(self.word, self.label)\n",
    "        return '({0} <- [{1}:{2}] -> {3})'.format(self.left, self.word, self.label, self.right)\n",
    "\n",
    "\n",
    "class Tree:\n",
    "\n",
    "    def __init__(self, treeString, openChar='(', closeChar=')'):\n",
    "        tokens = []\n",
    "        self.open = '('\n",
    "        self.close = ')'\n",
    "        for toks in treeString.strip().split():\n",
    "            tokens += list(toks)\n",
    "        self.root = self.parse(tokens)\n",
    "        # get list of labels as obtained through a post-order traversal\n",
    "        self.labels = get_labels(self.root)\n",
    "        self.num_words = len(self.labels)\n",
    "\n",
    "    def parse(self, tokens, parent=None):\n",
    "        assert tokens[0] == self.open, \"Malformed tree\"\n",
    "        assert tokens[-1] == self.close, \"Malformed tree\"\n",
    "\n",
    "        split = 2  # position after open and label\n",
    "        countOpen = countClose = 0\n",
    "\n",
    "        if tokens[split] == self.open:\n",
    "            countOpen += 1\n",
    "            split += 1\n",
    "        # Find where left child and right child split\n",
    "        while countOpen != countClose:\n",
    "            if tokens[split] == self.open:\n",
    "                countOpen += 1\n",
    "            if tokens[split] == self.close:\n",
    "                countClose += 1\n",
    "            split += 1\n",
    "\n",
    "        # New node\n",
    "        node = Node(int(tokens[1]))  # zero index labels\n",
    "\n",
    "        node.parent = parent\n",
    "\n",
    "        # leaf Node\n",
    "        if countOpen == 0:\n",
    "            node.word = ''.join(tokens[2: -1]).lower()  # lower case?\n",
    "            node.isLeaf = True\n",
    "            return node\n",
    "\n",
    "        node.left = self.parse(tokens[2: split], parent=node)\n",
    "        node.right = self.parse(tokens[split: -1], parent=node)\n",
    "\n",
    "        return node\n",
    "\n",
    "    def get_words(self):\n",
    "        leaves = getLeaves(self.root)\n",
    "        words = [node.word for node in leaves]\n",
    "        return words\n",
    "\n",
    "\n",
    "def get_labels(node):\n",
    "    if node is None:\n",
    "        return []\n",
    "    return get_labels(node.left) + get_labels(node.right) + [node.label]\n",
    "\n",
    "\n",
    "def getLeaves(node):\n",
    "    if node is None:\n",
    "        return []\n",
    "    if node.isLeaf:\n",
    "        return [node]\n",
    "    else:\n",
    "        return getLeaves(node.left) + getLeaves(node.right)\n",
    "\n",
    "\n",
    "def loadTrees(dataSet='train', transformer=True):\n",
    "    \"\"\"\n",
    "    Loads training trees. Maps leaf node words to word ids.\n",
    "    \"\"\"\n",
    "    file = '../dataset/trees/%s.txt' % dataSet\n",
    "    print(\"Loading %s trees..\" % dataSet)\n",
    "    with open(file, 'r', encoding='utf-8') as fid:\n",
    "        if transformer:\n",
    "            trees = [Tree(l) for l in fid.readlines()]\n",
    "        else:\n",
    "            trees = [l for l in fid.readlines()]\n",
    "\n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:34.947989Z",
     "iopub.status.busy": "2023-07-26T14:17:34.947716Z",
     "iopub.status.idle": "2023-07-26T14:17:36.935479Z",
     "shell.execute_reply": "2023-07-26T14:17:36.934813Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train trees..\n"
     ]
    }
   ],
   "source": [
    "train_data = loadTrees('train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Vocab "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:36.938843Z",
     "iopub.status.busy": "2023-07-26T14:17:36.938549Z",
     "iopub.status.idle": "2023-07-26T14:17:37.339130Z",
     "shell.execute_reply": "2023-07-26T14:17:37.338335Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab = list(set(flatten([t.get_words() for t in train_data])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:37.342646Z",
     "iopub.status.busy": "2023-07-26T14:17:37.342344Z",
     "iopub.status.idle": "2023-07-26T14:17:37.354714Z",
     "shell.execute_reply": "2023-07-26T14:17:37.354184Z"
    }
   },
   "outputs": [],
   "source": [
    "word2index = {'<UNK>': 0}\n",
    "for vo in vocab:\n",
    "    if word2index.get(vo) is None:\n",
    "        word2index[vo] = len(word2index)\n",
    "\n",
    "index2word = {v: k for k, v in word2index.items()}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"../images/09.rntn-layer.png\">\n",
    "<center>borrowed image from https://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:37.357516Z",
     "iopub.status.busy": "2023-07-26T14:17:37.357242Z",
     "iopub.status.idle": "2023-07-26T14:17:37.368386Z",
     "shell.execute_reply": "2023-07-26T14:17:37.367877Z"
    }
   },
   "outputs": [],
   "source": [
    "class RNTN(nn.Cell):\n",
    "\n",
    "    def __init__(self, word2index, hidden_size, output_size):\n",
    "        super(RNTN, self).__init__()\n",
    "\n",
    "        self.word2index = word2index\n",
    "        self.embed = nn.Embedding(len(word2index), hidden_size, embedding_table=\"XavierUniform\")\n",
    "        self.param_list = [Parameter(ops.randn(hidden_size * 2, hidden_size * 2), name=f\"param_{i}\") for i in range(hidden_size)]\n",
    "        self.W = Parameter(ops.randn(hidden_size * 2, hidden_size))\n",
    "        self.b = Parameter(ops.randn(1, hidden_size))\n",
    "        self.V = ParameterTuple(self.param_list)\n",
    "        self.W_out = nn.Dense(hidden_size, output_size, weight_init=\"XavierUniform\")\n",
    "\n",
    "    def tree_propagation(self, node):\n",
    "\n",
    "        recursive_tensor = OrderedDict()\n",
    "        current = None\n",
    "        if node.isLeaf:\n",
    "            tensor = Tensor([self.word2index[node.word]], dtype=mindspore.int64) if node.word in self.word2index.keys() \\\n",
    "                else Tensor([self.word2index['<UNK>']], dtype=mindspore.int64)\n",
    "            current = self.embed(tensor)  # 1xD\n",
    "        else:\n",
    "            recursive_tensor.update(self.tree_propagation(node.left))\n",
    "            recursive_tensor.update(self.tree_propagation(node.right))\n",
    "\n",
    "            concated = ops.cat([recursive_tensor[node.left], recursive_tensor[node.right]], 1)  # 1x2D\n",
    "            xVx = []\n",
    "            for i, v in enumerate(self.V):\n",
    "                xVx.append(ops.matmul(ops.matmul(concated, v), ops.transpose(concated, (1, 0))))\n",
    "\n",
    "            xVx = ops.cat(xVx, 1)  # 1xD\n",
    "            Wx = ops.matmul(concated, self.W)  # 1xD\n",
    "\n",
    "            current = ops.tanh(xVx + Wx + self.b)  # 1xD\n",
    "        recursive_tensor[node] = current\n",
    "        return recursive_tensor\n",
    "\n",
    "    def init_weight(self):\n",
    "        for param in self.param_list:\n",
    "            param.set_data(initializer(\"xavier_uniform\", param.shape))\n",
    "        self.V = ParameterTuple(self.param_list)\n",
    "        self.W.set_data(initializer('xavier_uniform', self.W.shape))\n",
    "        self.b.set_data(initializer('zeros', self.b.shape))\n",
    "\n",
    "    def construct(self, Trees, root_only=False):\n",
    "        if not isinstance(Trees, list):\n",
    "            Trees = [Trees]\n",
    "\n",
    "        propagated = []\n",
    "\n",
    "        for tree in Trees:\n",
    "            recursive_tensor = self.tree_propagation(tree.root)\n",
    "            if root_only:\n",
    "                recursive_tensor = recursive_tensor[tree.root]\n",
    "                propagated.append(recursive_tensor)\n",
    "            else:\n",
    "                recursive_tensor = [tensor for node, tensor in recursive_tensor.items()]\n",
    "                propagated.extend(recursive_tensor)\n",
    "\n",
    "        propagated = ops.cat(propagated)  # (num_of_node in batch, D)\n",
    "\n",
    "        return ops.log_softmax(self.W_out(propagated), 1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It takes for a while... It builds its computational graph dynamically. So Its computation is difficult to train with batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:37.371353Z",
     "iopub.status.busy": "2023-07-26T14:17:37.370950Z",
     "iopub.status.idle": "2023-07-26T14:17:37.373891Z",
     "shell.execute_reply": "2023-07-26T14:17:37.373423Z"
    }
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 30\n",
    "ROOT_ONLY = False\n",
    "BATCH_SIZE = 20\n",
    "EPOCH = 20\n",
    "LR = 0.015\n",
    "LAMBDA = 1e-5\n",
    "RESCHEDULED = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:37.376161Z",
     "iopub.status.busy": "2023-07-26T14:17:37.375889Z",
     "iopub.status.idle": "2023-07-26T14:17:40.399800Z",
     "shell.execute_reply": "2023-07-26T14:17:40.399146Z"
    }
   },
   "outputs": [],
   "source": [
    "model = RNTN(word2index, HIDDEN_SIZE, 5)\n",
    "model.init_weight()\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = nn.Adam(model.trainable_params(), learning_rate=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:40.402761Z",
     "iopub.status.busy": "2023-07-26T14:17:40.402478Z",
     "iopub.status.idle": "2023-07-26T14:17:40.433275Z",
     "shell.execute_reply": "2023-07-26T14:17:40.432691Z"
    }
   },
   "outputs": [],
   "source": [
    "accumulate_step = 2\n",
    "accumulator = Accumulator(optimizer, accumulate_step)\n",
    "\n",
    "\n",
    "def forward_fn():\n",
    "    \"\"\"Forward function\"\"\"\n",
    "    if ROOT_ONLY:\n",
    "        labels = [tree.labels[-1] for tree in batch]\n",
    "        labels = Tensor(labels, dtype=mindspore.int32)\n",
    "    else:\n",
    "        labels = [tree.labels for tree in batch]\n",
    "        labels = Tensor(flatten(labels), dtype=mindspore.int32)\n",
    "    preds = model(batch, ROOT_ONLY)\n",
    "    loss = loss_function(preds, labels)\n",
    "    return loss / accumulate_step\n",
    "\n",
    "\n",
    "# Get gradient function\n",
    "grad_fn = mindspore.value_and_grad(forward_fn, None, model.trainable_params())\n",
    "\n",
    "\n",
    "# Define function of one-step training\n",
    "def train_step():\n",
    "    \"\"\"Training steps\"\"\"\n",
    "    loss, grads = grad_fn()\n",
    "    loss = ops.depend(loss, accumulator(grads))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-07-26T14:17:40.435760Z",
     "iopub.status.busy": "2023-07-26T14:17:40.435507Z",
     "iopub.status.idle": "2023-08-03T04:59:28.027748Z",
     "shell.execute_reply": "2023-08-03T04:59:28.026084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0/20] mean_loss : 1.61\n",
      "[0/20] mean_loss : 1.26\n",
      "[0/20] mean_loss : 1.01\n",
      "[0/20] mean_loss : 0.95\n",
      "[0/20] mean_loss : 0.91\n",
      "[1/20] mean_loss : 0.88\n",
      "[1/20] mean_loss : 0.90\n",
      "[1/20] mean_loss : 0.89\n",
      "[1/20] mean_loss : 0.90\n",
      "[1/20] mean_loss : 0.89\n",
      "[2/20] mean_loss : 0.86\n",
      "[2/20] mean_loss : 0.88\n",
      "[2/20] mean_loss : 0.88\n",
      "[2/20] mean_loss : 0.87\n",
      "[2/20] mean_loss : 0.86\n",
      "[3/20] mean_loss : 0.86\n",
      "[3/20] mean_loss : 0.85\n",
      "[3/20] mean_loss : 0.84\n",
      "[3/20] mean_loss : 0.85\n",
      "[3/20] mean_loss : 0.85\n",
      "[4/20] mean_loss : 0.91\n",
      "[4/20] mean_loss : 0.84\n",
      "[4/20] mean_loss : 0.84\n",
      "[4/20] mean_loss : 0.84\n",
      "[4/20] mean_loss : 0.85\n",
      "[5/20] mean_loss : 0.82\n",
      "[5/20] mean_loss : 0.85\n",
      "[5/20] mean_loss : 0.87\n",
      "[5/20] mean_loss : 0.92\n",
      "[5/20] mean_loss : 0.90\n",
      "[6/20] mean_loss : 0.90\n",
      "[6/20] mean_loss : 0.90\n",
      "[6/20] mean_loss : 0.89\n",
      "[6/20] mean_loss : 0.89\n",
      "[6/20] mean_loss : 0.89\n",
      "[7/20] mean_loss : 0.85\n",
      "[7/20] mean_loss : 0.88\n",
      "[7/20] mean_loss : 0.88\n",
      "[7/20] mean_loss : 0.90\n",
      "[7/20] mean_loss : 0.88\n",
      "[8/20] mean_loss : 0.85\n",
      "[8/20] mean_loss : 0.88\n",
      "[8/20] mean_loss : 0.88\n",
      "[8/20] mean_loss : 0.88\n",
      "[8/20] mean_loss : 0.88\n",
      "[9/20] mean_loss : 0.93\n",
      "[9/20] mean_loss : 0.87\n",
      "[9/20] mean_loss : 0.87\n",
      "[9/20] mean_loss : 0.88\n",
      "[9/20] mean_loss : 0.88\n",
      "[10/20] mean_loss : 0.95\n",
      "[10/20] mean_loss : 0.87\n",
      "[10/20] mean_loss : 0.87\n",
      "[10/20] mean_loss : 0.86\n",
      "[10/20] mean_loss : 0.86\n",
      "[11/20] mean_loss : 0.93\n",
      "[11/20] mean_loss : 0.86\n",
      "[11/20] mean_loss : 0.86\n",
      "[11/20] mean_loss : 0.86\n",
      "[11/20] mean_loss : 0.86\n",
      "[12/20] mean_loss : 0.88\n",
      "[12/20] mean_loss : 0.86\n",
      "[12/20] mean_loss : 0.85\n",
      "[12/20] mean_loss : 0.85\n",
      "[12/20] mean_loss : 0.86\n",
      "[13/20] mean_loss : 0.96\n",
      "[13/20] mean_loss : 0.85\n",
      "[13/20] mean_loss : 0.85\n",
      "[13/20] mean_loss : 0.86\n",
      "[13/20] mean_loss : 0.86\n",
      "[14/20] mean_loss : 0.84\n",
      "[14/20] mean_loss : 0.85\n",
      "[14/20] mean_loss : 0.85\n",
      "[14/20] mean_loss : 0.85\n",
      "[14/20] mean_loss : 0.86\n",
      "[15/20] mean_loss : 0.91\n",
      "[15/20] mean_loss : 0.85\n",
      "[15/20] mean_loss : 0.84\n",
      "[15/20] mean_loss : 0.85\n",
      "[15/20] mean_loss : 0.85\n",
      "[16/20] mean_loss : 0.85\n",
      "[16/20] mean_loss : 0.85\n",
      "[16/20] mean_loss : 0.86\n",
      "[16/20] mean_loss : 0.85\n",
      "[16/20] mean_loss : 0.85\n",
      "[17/20] mean_loss : 0.92\n",
      "[17/20] mean_loss : 0.85\n",
      "[17/20] mean_loss : 0.86\n",
      "[17/20] mean_loss : 0.85\n",
      "[17/20] mean_loss : 0.85\n",
      "[18/20] mean_loss : 0.88\n",
      "[18/20] mean_loss : 0.85\n",
      "[18/20] mean_loss : 0.85\n",
      "[18/20] mean_loss : 0.85\n",
      "[18/20] mean_loss : 0.85\n",
      "[19/20] mean_loss : 0.80\n",
      "[19/20] mean_loss : 0.84\n",
      "[19/20] mean_loss : 0.84\n",
      "[19/20] mean_loss : 0.86\n",
      "[19/20] mean_loss : 0.85\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(EPOCH):\n",
    "    losses = []\n",
    "\n",
    "    # learning rate annealing\n",
    "    if RESCHEDULED is False and epoch == EPOCH // 2:\n",
    "        LR *= 0.1\n",
    "        optimizer = nn.Adam(model.trainable_params(), learning_rate=LR, weight_decay=LAMBDA)  # L2 norm\n",
    "        accumulator = Accumulator(optimizer, accumulate_step)\n",
    "        RESCHEDULED = True\n",
    "\n",
    "    for i, batch in enumerate(getBatch(BATCH_SIZE, train_data)):\n",
    "        loss = train_step()\n",
    "        losses.append(loss.asnumpy().item(0) * accumulate_step)\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print('[%d/%d] mean_loss : %.2f' % (epoch, EPOCH, np.mean(losses)))\n",
    "            losses = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The convergence of the model is unstable according to the initial values. I tried to 5~6 times for this."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-03T04:59:28.034949Z",
     "iopub.status.busy": "2023-08-03T04:59:28.034412Z",
     "iopub.status.idle": "2023-08-03T04:59:28.409920Z",
     "shell.execute_reply": "2023-08-03T04:59:28.409300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test trees..\n"
     ]
    }
   ],
   "source": [
    "test_data = loadTrees('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2023-08-03T04:59:28.414321Z",
     "iopub.status.busy": "2023-08-03T04:59:28.414032Z",
     "iopub.status.idle": "2023-08-03T04:59:28.417245Z",
     "shell.execute_reply": "2023-08-03T04:59:28.416747Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = 0\n",
    "num_node = 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-grained all"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In paper, they acheived 80.2 accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-08-03T04:59:28.419671Z",
     "iopub.status.busy": "2023-08-03T04:59:28.419380Z",
     "iopub.status.idle": "2023-08-03T05:03:31.455094Z",
     "shell.execute_reply": "2023-08-03T05:03:31.454356Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "67.51089588377724\n"
     ]
    }
   ],
   "source": [
    "for test in test_data:\n",
    "    preds = model(test, ROOT_ONLY)\n",
    "    labels = test.labels[-1:] if ROOT_ONLY else test.labels\n",
    "    for pred, label in zip(ops.max(preds, 1)[1].asnumpy(), labels):\n",
    "        num_node += 1\n",
    "        if pred == label:\n",
    "            accuracy += 1\n",
    "\n",
    "print(accuracy / num_node * 100)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* https://github.com/nearai/pytorch-tools # Dynamic batch using TensorFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Further topics "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* <a href=\"https://arxiv.org/pdf/1503.00075.pdf\">Improved Semantic Representations From Tree-Structured Long Short-Term Memory Networks</a>\n",
    "* <a href=\"https://arxiv.org/abs/1603.06021\">A Fast Unified Model for Parsing and Sentence Understanding(SPINN)</a>\n",
    "* <a href=\"https://devblogs.nvidia.com/parallelforall/recursive-neural-networks-pytorch/?utm_campaign=Revue%20newsletter&utm_medium=Newsletter&utm_source=revue\">Posting about SPINN</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
